{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "![Task1a](Task_1a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "![Task1b](Task_1b.png)\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "![Task1c1](Task_1c1.png)\n",
    "\n",
    "![Task1c2](Task_1c2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2f)\n",
    "\n",
    "![Task2f](task2\\precision_recall_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "\n",
    "![Task3a](Task_3a.png)\n",
    "\n",
    "### Task 3b)\n",
    "\n",
    "![Task3b](Task_3b.png)\n",
    "\n",
    "### Task 3c)\n",
    "\n",
    "![Task3c](Task_3c.png)\n",
    "\n",
    "### Task 3d)\n",
    "\n",
    "![Task3d](Task_3d.png)\n",
    "\n",
    "### Task 3e)\n",
    "\n",
    "![Task3e](Task_3e.png)\n",
    "\n",
    "### Task 3f)\n",
    "\n",
    "![Task3f](Task_3f.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "Total loss over 10 000 iterations:\n",
    "\n",
    "![Task4b_loss](SSD\\Total_loss_task4b.png)\n",
    "\n",
    "The final mAP after 10 000 iterations was 0.8011.\n",
    "\n",
    "mAP over 10 000 iterations:\n",
    "\n",
    "![Task4b_mAP](SSD\\mAP_task4b.png)\n",
    "\n",
    "Class distributed mAP:\n",
    "\n",
    "| Class | mAP |\n",
    "| :-: | :-: |\n",
    "| 0 | 0.8511 |\n",
    "| 1 | 0.7240 |\n",
    "| 2 | 0.7841 |\n",
    "| 3 | 0.8185 |\n",
    "| 4 | 0.8255 |\n",
    "| 5 | 0.8061 |\n",
    "| 6 | 0.8109 |\n",
    "| 7 | 0.8036 |\n",
    "| 8 | 0.8087 |\n",
    "| 9 | 0.7788 |\n",
    "\n",
    "## Task 4c)\n",
    "\n",
    "The model used in 4c and 4d was implemented in improved.py in the backbone folder.\n",
    "\n",
    "To reach 85% I first added batch normalization which sped up the convergence of the training but the mAP flattened very early. Next I doubled the number of filters in all the layers, which gave me around 84% mAP. Then I doubled the number of filters again but this did not increase the mAP so I tried adding dropout of 10% after each convolutional layer to counteract overfitting and this pushed the mAP to 87,5%.\n",
    "\n",
    "Total loss over 10 000 iterations:\n",
    "\n",
    "![Task4c_loss](SSD\\Total_loss_task4c.png)\n",
    "\n",
    "Final mAP: 0.8753\n",
    "\n",
    "mAP over 10 000 iterations:\n",
    "\n",
    "![Task4c_mAP](SSD\\mAP_task4c.png)\n",
    "\n",
    "Class distributed mAP:\n",
    "\n",
    "| Class | mAP |\n",
    "| :-: | :-: |\n",
    "| 0 | 0.8940 |\n",
    "| 1 | 0.8096 |\n",
    "| 2 | 0.8760 |\n",
    "| 3 | 0.8971 |\n",
    "| 4 | 0.8807 |\n",
    "| 5 | 0.8830 |\n",
    "| 6 | 0.8859 |\n",
    "| 7 | 0.8569 |\n",
    "| 8 | 0.8900 |\n",
    "| 9 | 0.8794 |\n",
    "\n",
    "\n",
    "## Task 4d)\n",
    "\n",
    "The model had a hard time detecting class 1 and i suspected this might be a small object. To improve on this i reduced the smallest minimum size in MIN_SIZES to [20, 20] in the configuration. This made the learning unstable so I also had to reduce learn rate to $10^{-3}$ instead of $2*10^{-3}$. This change pushed the mAP to around 89.5%, and to get the final boost I increased the IoU threshold to 0.7 and reduced the smallest minimum size further to [10, 10]. Again this caused unstable learning which I fixed by reducing learn rate to $5*10^{-4}$. These changes pushed the mAP to 90%.\n",
    "\n",
    "Total loss over 15 000 iterations:\n",
    "\n",
    "![Task4c_loss](SSD\\Total_loss_task4d.png)\n",
    "\n",
    "The final mAP after 15000 iterations was 0.9018.\n",
    "\n",
    "mAP over 15 000 iterations:\n",
    "\n",
    "![Task4c_mAP](SSD\\mAP_task4d.png)\n",
    "\n",
    "Class distributed mAP:\n",
    "\n",
    "| Class | mAP |\n",
    "| :-: | :-: |\n",
    "| 0 | 0.9078 |\n",
    "| 1 | 0.8646 |\n",
    "| 2 | 0.9052 |\n",
    "| 3 | 0.9064 |\n",
    "| 4 | 0.9060 |\n",
    "| 5 | 0.9075 |\n",
    "| 6 | 0.9061 |\n",
    "| 7 | 0.9026 |\n",
    "| 8 | 0.9083 |\n",
    "| 9 | 0.9036 |\n",
    "\n",
    "\n",
    "\n",
    "## Task 4e)\n",
    "\n",
    "Below are classified images from the demo folder, classified with the model which reached 87% accuracy. I chose to use this model as it has a lower IoU threshold resulting in more digits being detected than when using the model with 90% accuracy. From the images we can see that the model struggles detecting digits that are small in size. This is a common problem when using SSD, it often struggles detecting small objects. Increasing the resolution of the input images could help reduce this problem at the cost of longer computing time for both training and inference.\n",
    "\n",
    "![Task4e0](SSD/demo/mnist/result/0.png)\n",
    "\n",
    "![Task4e1](SSD/demo/mnist/result/1.png)\n",
    "\n",
    "![Task4e2](SSD/demo/mnist/result/2.png)\n",
    "\n",
    "![Task4e3](SSD/demo/mnist/result/3.png)\n",
    "\n",
    "![Task4e4](SSD/demo/mnist/result/4.png)\n",
    "\n",
    "![Task4e5](SSD/demo/mnist/result/5.png)\n",
    "\n",
    "![Task4e6](SSD/demo/mnist/result/6.png)\n",
    "\n",
    "![Task4e7](SSD/demo/mnist/result/7.png)\n",
    "\n",
    "![Task4e8](SSD/demo/mnist/result/8.png)\n",
    "\n",
    "![Task4e9](SSD/demo/mnist/result/9.png)\n",
    "\n",
    "![Task4e10](SSD/demo/mnist/result/10.png)\n",
    "\n",
    "![Task4e11](SSD/demo/mnist/result/11.png)\n",
    "\n",
    "![Task4e12](SSD/demo/mnist/result/12.png)\n",
    "\n",
    "![Task4e13](SSD/demo/mnist/result/13.png)\n",
    "\n",
    "![Task4e14](SSD/demo/mnist/result/14.png)\n",
    "\n",
    "## Task 4f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
