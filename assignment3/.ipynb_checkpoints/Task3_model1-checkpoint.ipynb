{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from torch import nn\n",
    "from dataloaders import load_cifar10\n",
    "from trainer import Trainer, compute_loss_and_accuracy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 image_channels,\n",
    "                 num_classes):\n",
    "        \"\"\"\n",
    "            Is called when model is initialized.\n",
    "            Args:\n",
    "                image_channels. Number of color channels in image (3)\n",
    "                num_classes: Number of classes we want to predict (10)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # TODO: Implement this function (Task  2a)\n",
    "        num_filters = [64, 128, 256]  # Set number of filters in each conv layer\n",
    "        self.num_classes = num_classes\n",
    "        # Define the first convolutional layer\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=image_channels,\n",
    "                out_channels=num_filters[0],\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = num_filters[0]),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2\n",
    "            )\n",
    "        )\n",
    "        # Define the rest of the convolutional layers\n",
    "        for i in range(1, len(num_filters)):\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                self.feature_extractor,\n",
    "                nn.Conv2d(\n",
    "                    in_channels=num_filters[i-1],\n",
    "                    out_channels=num_filters[i],\n",
    "                    kernel_size=5,\n",
    "                    stride=1,\n",
    "                    padding=2\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(num_features = num_filters[i]),\n",
    "                nn.MaxPool2d(\n",
    "                    kernel_size=2,\n",
    "                    stride=2\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.num_output_features = 4*4*256\n",
    "        # Initialize the first fully connected layer\n",
    "        # Inputs all extracted features from the convolutional layers\n",
    "        num_nodes = 64\n",
    "        # Outputs num_nodes features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.num_output_features, num_nodes),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features = num_nodes)\n",
    "        )\n",
    "        # Initialize the final fully connected layer\n",
    "        # Inputs num_nodes features\n",
    "        # Outputs num_classes predictions, 1 for each class.\n",
    "        # There is no need for softmax activation function, as this is\n",
    "        # included with nn.CrossEntropyLoss\n",
    "        self.classifier = nn.Sequential(\n",
    "            self.classifier,\n",
    "            nn.Linear(num_nodes, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the model\n",
    "        Args:\n",
    "            x: Input image, shape: [batch_size, 3, 32, 32]\n",
    "        \"\"\"\n",
    "        # TODO: Implement this function (Task  2a)\n",
    "        batch_size = x.shape[0]\n",
    "        out = self.feature_extractor(x)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.classifier(out)\n",
    "        expected_shape = (batch_size, self.num_classes)\n",
    "        assert out.shape == (batch_size, self.num_classes),\\\n",
    "            f\"Expected output of forward pass to be: {expected_shape}, but got: {out.shape}\"\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (1): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (2): ReLU()\n",
      "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (2): ReLU()\n",
      "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Using SGD optimizer\n",
      "Epoch: 0, Batches per seconds: 81.01, Global step:    703, Validation Loss: 1.07, Validation Accuracy: 0.621\n",
      "Epoch: 0, Batches per seconds: 93.82, Global step:   1406, Validation Loss: 0.93, Validation Accuracy: 0.675\n",
      "Epoch: 1, Batches per seconds: 97.73, Global step:   2109, Validation Loss: 0.81, Validation Accuracy: 0.713\n",
      "Epoch: 1, Batches per seconds: 102.23, Global step:   2812, Validation Loss: 0.72, Validation Accuracy: 0.755\n",
      "Epoch: 2, Batches per seconds: 103.77, Global step:   3515, Validation Loss: 0.72, Validation Accuracy: 0.747\n",
      "Epoch: 2, Batches per seconds: 105.66, Global step:   4218, Validation Loss: 0.69, Validation Accuracy: 0.769\n",
      "Epoch: 3, Batches per seconds: 105.82, Global step:   4921, Validation Loss: 0.76, Validation Accuracy: 0.768\n",
      "Epoch: 3, Batches per seconds: 107.14, Global step:   5624, Validation Loss: 0.70, Validation Accuracy: 0.777\n",
      "Epoch: 4, Batches per seconds: 107.40, Global step:   6327, Validation Loss: 0.76, Validation Accuracy: 0.763\n",
      "Early stop criteria met\n",
      "Early stopping.\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 5e-2\n",
    "early_stop_count = 4\n",
    "dataloaders = load_cifar10(batch_size)\n",
    "model = Model(image_channels=3, num_classes=10)\n",
    "trainer = Trainer(\n",
    "    batch_size,\n",
    "    learning_rate,\n",
    "    early_stop_count,\n",
    "    epochs,\n",
    "    model,\n",
    "    dataloaders\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_best_model()\n",
    "model = trainer.model\n",
    "dataloader_train, dataloader_val, dataloader_test = dataloaders\n",
    "train_loss, train_acc = compute_loss_and_accuracy(\n",
    "    dataloader_train, model, nn.CrossEntropyLoss()\n",
    ")\n",
    "validation_loss, validation_acc = compute_loss_and_accuracy(\n",
    "    dataloader_val, model, nn.CrossEntropyLoss()\n",
    ")\n",
    "test_loss, test_acc = compute_loss_and_accuracy(\n",
    "    dataloader_test, model, nn.CrossEntropyLoss()\n",
    ")\n",
    "print(\"Best model training accuracy:\", train_acc)\n",
    "print(\"Best model validation accuracy:\", validation_acc)\n",
    "print(\"Best model test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
